<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Chip Data from HSU</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/lumen.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">PGS|Consistency</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="index.html">Introduction</a>
</li>
<li>
  <a href="0_PredictorPrep.html">Predictors</a>
</li>
<li>
  <a href="1_GRP_ChipData.html">HSU Data</a>
</li>
<li>
  <a href="2_QIMR_ChipData.html">QIMR Data</a>
</li>
<li>
  <a href="3_WGS.html">WGS data</a>
</li>
<li>
  <a href="4_LowPassSeq.html">lcWGS data</a>
</li>
<li>
  <a href="5_Consistency.html">Consistency</a>
</li>
<li>
  <a href="10_Imputation_Panel_effect.html">Imputation Panel</a>
</li>
<li>
  <a href="6_MissingSNP.html">Missingness</a>
</li>
<li>
  <a href="7_Benchmarking.html">Benchmarking</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Chip Data from HSU</h1>

</div>


<hr />
<p>Two CEPH samples were used as technical control in HSU lab. They were
genotyped with each batch of samples processed and genotyped in the lab.
Genotype data were exported into Plink format, includes a MAP file and
PED file, using Genome Studio.</p>
<p>We have developed an in-house pipeline for processing the raw plink
data all the way to profiling their GPS of interested traits.</p>
<div id="pre-imputation-processing" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Pre-imputation
processing</h1>
<div id="convert-to-binary-format" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> convert to binary
format</h2>
<p>We usually transfer the data to binary format to save space and
accelerate calculation speed.</p>
<pre class="bash"><code>
plink \
--file ${inpath}/${data}  \
--make-bed --out ${dir}/Original/${data}</code></pre>
<p>This format is explained well in <a
href="https://zzz.bwh.harvard.edu/plink/data.shtml#bed">plink manual
page</a>.</p>
</div>
<div id="match-missing-alleles" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> match missing
alleles</h2>
<p>Since the sample size in each batch is very small, a lot of SNPs
didn’t get alternative alleles in the data. We filled in the alternative
allele in bim file by matching to the strand file of the chip.</p>
<pre class="r"><code>args=commandArgs(trailingOnly = T)
bim.file = args[1]
strand.file = args[2]

bim =  read.table(bim.file)
strand.A = read.table(strand.file)

bim$strand = strand.A[match(bim$V2, strand.A$V1),&quot;V6&quot;]
bim$index = c(1:nrow(bim))
bim.tofill = bim[(bim[,&quot;V5&quot;] == 0 &amp; bim[,&quot;V6&quot;] != 0 &amp; bim[,&quot;strand&quot;]%in%
                      c(&quot;AT&quot;, &quot;CG&quot;, &quot;AC&quot;, &quot;AG&quot;, &quot;CT&quot;, &quot;CA&quot;,&quot;GA&quot;, &quot;GT&quot;, &quot;GC&quot;,&quot;TA&quot;,&quot;TC&quot;,&quot;TG&quot; )), ]
bim.nottofill = bim[!bim$V2%in%bim.tofill$V2,]

for(i in 1:nrow(bim.tofill)){
    bim.tofill[i,&quot;V5&quot;] = gsub(bim.tofill[i,&quot;V6&quot;], &quot;&quot; , bim.tofill[i, &quot;strand&quot;])
  }

bim.c = rbind(bim.tofill, bim.nottofill)
bim.c = bim.c[order(bim.c$index),]
write.table(bim.c[,1:6], file=paste0(bim.file, &quot;_missing_filled.txt&quot;), 
            quote = F, sep =&quot;\t&quot;, row.names = F, col.names = F)</code></pre>
</div>
<div id="quality" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Quality</h2>
<p>We use Plink to generate summary stats at per-SNP and per-individual
levels.</p>
<pre class="bash"><code>plink  --bfile ${dir}/Original/${data}  --missing   --out   ${dir}/Original/${data}
plink  --bfile ${dir}/Original/${data}  --freq      --out   ${dir}/Original/${data}
plink  --bfile ${dir}/Original/${data}  --hardy     --out   ${dir}/Original/${data}</code></pre>
<p>We used R to read in and make histograms of the summary
statistics.</p>
<pre class="r"><code>filename=&quot;target&quot;

imiss &lt;- read.table(paste0(filename,&quot;.imiss&quot;), header=T, check.names=F)
lmiss &lt;- read.table(paste0(filename,&quot;.lmiss&quot;), header=T, check.names=F)
freq &lt;- read.table(paste0(filename,&quot;.frq&quot;), header=T,    check.names=F)
hwe &lt;- read.table(paste0(filename,&quot;.hwe&quot;), header=T,   check.names=F)

# You can either run the plotting function in interactive Jupyter R. 
# Or un-mute the png and dev.off command lines to save the picture. 

#png(paste0(filename,&quot;_Quality_of_genotype.png&quot;), type=&quot;cairo&quot;)
par(mfrow=c(2,2))
hist(1-imiss$F_MISS, breaks=&quot;sturges&quot;,main=&quot;Individuals&quot;,col=&quot;tan&quot;, 
     xlab=&quot;Genotyping Rate&quot;, ylab=&quot;Number of Individuals&quot;)
hist(1-lmiss$F_MISS, breaks=&quot;sturges&quot;, main=&quot;SNPs&quot;, col=&quot;tan&quot;, 
     xlab=&quot;Genotyping Rate&quot;, ylab=&quot;Number of SNPs&quot;)
hist(hwe$P, breaks=&quot;sturges&quot;, main=&quot;HWE P-Value&quot;, col=&quot;tan&quot;, 
     xlab=&quot;HWE P-value&quot;, ylab=&quot;Number of SNPs&quot;)
hist(freq$MAF, breaks=&quot;sturges&quot;, main=&quot;MAF&quot;, col=&quot;tan&quot;, 
     xlab=&quot;MAF&quot;, ylab=&quot;Number of SNPs&quot;)
#dev.off()</code></pre>
</div>
<div id="sex-check" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Sex check</h2>
<p>As a very useful way to confirm that the samples were not messed up
in handling, we predict sex from heterozygosity in chromosome X, and
compare it to the sex in phenotype column in the fam file.</p>
<p>A PROBLEM arises if the two sexes do not match, or if the SNP data or
pedigree data are ambiguous with regard to sex. More details are in <a
href="https://zzz.bwh.harvard.edu/plink/summary.shtml#sexcheck">plink
manual page</a>.</p>
<p>We need chrX to do this check, but our predictor data has only
autosomes, so we will leave out the X chromosome in next step.</p>
<pre class="bash"><code># don&#39;t run this chunk with practical data. it does not have X chromosome
plink  --bfile ${dir}/Original/${data}  --check-sex --out  ${dir}/Original/${data}</code></pre>
</div>
<div id="flip-snps-on-minus-strand" class="section level2" number="1.5">
<h2><span class="header-section-number">1.5</span> Flip SNPs on minus
Strand</h2>
<p>The chips don’t always have probes on the positive strands. We have
to flip all the SNPs on minus strand to positive strand for matching to
reference data. <a href="https://www.strand.org.uk">Strand</a> website
has prepared strand files for a lot of chips. We downloaded the strand
data for each chip we used, and used the
<strong>update_build.sh</strong> tool to flip the strands.</p>
<p><img src="Figures/strand_display.png" width="300px" style="display: block; margin: auto;" /></p>
<pre class="bash"><code>plink --bfile ${dir}/Original/${data} --flip ${refdir}/$strand  --recode  --make-bed  --out  ${dir}/Original/flipped_${data}</code></pre>
</div>
<div id="qc" class="section level2" number="1.6">
<h2><span class="header-section-number">1.6</span> QC</h2>
<p>In QC step, we use Plink to exclude the SNPs and individuals with
high missingess, very low MAF, and SNPs that violate Hardy-Weinberg
Equilibrium.</p>
<pre class="bash"><code>
plink  \
 --bfile  ${dir}/Original/lipped_${data}  \
 --mind 0.05 \
 --geno 0.05 \
 --hwe 0.000001 \
 --make-bed  \
 --maf  0.01 \
 --out    ${dir}/Original/cleaned_flipped_${data}</code></pre>
<p>Parameters in the command:<br />
–mind: missingness per individual threshold<br />
–geno: missingness per SNP threshold<br />
–hwe: Hardy-Weinberg Equilibrium p-value threshold<br />
–maf: Minor allele frequency thresohld</p>
<p>It’s very often that our target data set has a small sample size,
around one or two hundred. Some cross-sample QC methods don’t work very
well in this circumstance. We made a QCed SNP list from pooled samples,
and use it to extract high quality SNPs from small batches.</p>
<pre class="bash"><code>plink --bfile    ${dir}/Original/flipped_${data}  \
--mind 0.05  \
--chr 1-22  QCedSNPs_Preimputed.txt  \
--make-bed  \
--out   ${dir}/Original/cleaned_flipped_${data}</code></pre>
</div>
</div>
<div id="data-imputation" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Data Imputation</h1>
<p>There are several online imputation servers you can use to impute
your data, such as <a
href="https://imputation.biodatacatalyst.nhlbi.nih.gov/#!">TOPMED
imputation server</a> and <a
href="https://imputation.sanger.ac.uk">Sanger imputation server</a>.
Here we will use open resource tools and the reference data <a
href="https://www.internationalgenome.org">1000Genome</a> to do it
in-house.</p>
<div id="fix-reference-allele" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Fix reference
allele</h2>
<p>We will convert the data from PLINK format to VCF format, and use
BCFTools to align the reference alleles as used in human genome
reference data.</p>
<pre class="bash"><code>chr=22

# Pull out data for relevant chromosome and convert to VCF. 
plink --bfile ${data}_chr${chr}  --recode vcf --out  ${data}_chr${chr}

# Sort and compress the VCF file
vcf-sort ${data}_chr${chr}.vcf | bgzip -c &gt; ${data}_chr${chr}.vcf.gz

# Fix the reference allele to match the GRCh37 reference fasta (human_g1k_v37.fasta). 
ref2fix=${refpath}/human_g1k_v37.fasta
BCFTOOLS_PLUGINS=/software/bin/
bcftools \
  +fixref \
  ${data}_chr${chr}.vcf.gz \
  -Oz \
  -o fixed_${data}_chr${chr}.vcf.gz  \
  -- -d \
  -f ${ref2fix} \
  -m flip

zcat fixed_${data}_chr${chr}.vcf.gz | bgzip -c &gt; indexed_fixed_${data}_chr${chr}.vcf.gz

# create index file. 
tabix indexed_fixed_${data}_chr${chr}.vcf.gz</code></pre>
</div>
<div id="phasing" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Phasing</h2>
<p>Although it is not required for all imputation softwares, here we
will reconstruct the haplotypes from our data with external information,
which is called phasing.</p>
<p>Both of the haplotype reference and genetic map used here are from <a
href="https://www.internationalgenome.org">1000Genome</a> project.</p>
<p>There are many phasing tools. We will use <a
href="https://alkesgroup.broadinstitute.org/Eagle/">Eagle v2.4.1</a> in
our practice.</p>
<pre class="bash"><code>
# Use EAGLE to generate phased haplotypes
    ${exedir}/tools/eagle \
            --vcfRef=${refdir}/HRC/HRC.r1-1.EGA.GRCh37.chr${chr}.haplotypes.vcf.gz  \
            --vcfTarget=${dir}/Fixed/cleaned_flipped_${data}_fixed_index_chr${chr}.vcf.gz  \
            --geneticMapFile=${refdir}/genetic_map_modified/genetic_map_chr${chr}_combined_b37_modified.txt \
            --vcfOutFormat=z \
            --numThreads=10 \
            --outPrefix=${dir}/Phased/${data}_phased_chr${chr} \
            2&gt;&amp;1 | tee ${dir}/Phased/${data}_phasing_chr${chr}.log


# index the vcf.gz file
tabix -p vcf  phased_chr${chr}.vcf.gz</code></pre>
</div>
<div id="imputation" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Imputation</h2>
<p>Imputation was done with chunks for time efficiency.</p>
<pre class="bash"><code># CAUTION: genetic map file is different from the one used in phasing!
# impute5 doesn&#39;t want the chr column in genetic map, so we removed that column

# Chunk details
chr=$(head -n ${SLURM_ARRAY_TASK_ID}      ${refdir}/HRC/chunk.list.${imputetool}.txt | tail -n 1  | awk &#39;{print $1}&#39; )
intstart=$(head -n ${SLURM_ARRAY_TASK_ID} ${refdir}/HRC/chunk.list.${imputetool}.txt | tail -n 1  | awk &#39;{print $3}&#39; )
intend=$(head -n ${SLURM_ARRAY_TASK_ID}   ${refdir}/HRC/chunk.list.${imputetool}.txt | tail -n 1  | awk &#39;{print $4}&#39; )
row=$(head -n ${SLURM_ARRAY_TASK_ID}      ${refdir}/HRC/chunk.list.${imputetool}.txt | tail -n 1  | awk &#39;{print $2}&#39; )

# impute chunks

    ${exedir}/tools/impute5_v1.1.5/impute5_1.1.5_static \
        --m  ${refdir}/1000GP_Phase3/genetic_map_chr${chr}_combined_b37.txt  \
        --h  ${refdir}/HRC/HRC.r1-1.EGA.GRCh37.chr${chr}.haplotypes.vcf.gz \
        --g  ${dir}/Phased/${data}_phased_chr${chr}.vcf.gz  \
        --r  ${chr}:${intstart}-${intend}  \
        --ne 20000   \
        --threads 1 \
        --o  ${dir}/Imputed_Chunks/${data}_${imputetool}_chr${chr}_${row}_imputed.vcf.gz \
        --l  ${dir}/Imputed_Chunks/${data}_${imputetool}_chr${chr}_${row}_imputed.log
</code></pre>
</div>
<div id="format-the-imputed-data" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> format the imputed
data</h2>
<p>Imputed data is output as a zipped VCF file. We will change the
format back to PLINK for following analysis.</p>
<p>We will use BCFTOOL again to extract info score for the imputed SNPs
from the VCF file, which stands for the imputation quality per SNP. Info
score is sensitive to sample size, so be careful to use it when you have
a very small sample size in real studies.</p>
<pre class="bash"><code>    filelist=$(ls  Imputed_Chunks/*vcf.gz | grep chr${TASK_ID}_    |   tr &#39;\t&#39;   &#39;\n&#39; | awk &#39;{print $1, $1}&#39; | sed &quot;s/Imputed_Chunks\/${data}_${imputetool}_chr${TASK_ID}_//&quot;  | sed &quot;s/_imputed.vcf.gz//&quot; | sort -g -k 1  | awk &#39;{print $2}&#39;  | tr &#39;\n&#39;   &#39;\t&#39;)

    ## merge
    bcftools concat -Oz -o ${dir}/Imputed_Chromosomes/${data}_${imputetool}_chr${TASK_ID}_imputed.vcf.gz  ${filelist}

    ## convert to plink format
    plink --vcf ${dir}/Imputed_Chromosomes/${data}_${imputetool}_chr${TASK_ID}_imputed.vcf.gz  \
    --const-fid \
    --keep-allele-order \
    --make-bed \
    --out  ${dir}/Imputed_Chromosomes/${data}_${imputetool}_imputed_chr${TASK_ID} 

    ## generate info score file
    tabix -p vcf   &quot;${dir}/Imputed_Chromosomes/${data}_${imputetool}_chr${TASK_ID}_imputed.vcf.gz&quot;
    bcftools query -f &#39;%CHROM\t%ID\t%QUAL\t%POS\t%REF\t%ALT\t%INFO/AF\t%INFO/INFO\n&#39; ${dir}&quot;/Imputed_Chromosomes/&quot;${data}&quot;_${imputetool}_chr&quot;${TASK_ID}&quot;_imputed.vcf.gz&quot; &gt; $dir&quot;/Imputed_Chromosomes/&quot;${data}&quot;_chr&quot;${TASK_ID}&quot;.info&quot;

    ## update RS IDs in plink data
    Rscript  $imputation_module/update_imputed_SNPs_from_${imputetool}.R  ${dir}/Imputed_Chromosomes/${data}_${imputetool}_imputed_chr${TASK_ID}.bim
    mv ${dir}/Imputed_Chromosomes/${data}_${imputetool}_imputed_chr${TASK_ID}.bim  ${dir}/Imputed_Chromosomes/${data}_${imputetool}_imputed_chr${TASK_ID}.bim_ori
    mv ${dir}/Imputed_Chromosomes/${data}_${imputetool}_imputed_chr${TASK_ID}.bim_refilled ${dir}/Imputed_Chromosomes/${data}_${imputetool}_imputed_chr${TASK_ID}.bim

    ## update RS IDs in info file
    Rscript  $imputation_module/update_imputed_SNPs_from_${imputetool}.R  &quot;${dir}/Imputed_Chromosomes/${data}_chr${TASK_ID}.info&quot;
    mv ${dir}/Imputed_Chromosomes/${data}_chr${TASK_ID}.info_refilled  ${dir}/Imputed_Chromosomes/${data}_imputed_chr${TASK_ID}_rs_updated.info

    ## fix fam IDs
    cp ${dir}/Imputed_Chromosomes/${data}_${imputetool}_imputed_chr${TASK_ID}.fam ${dir}/Imputed_Chromosomes/${data}_${imputetool}_imputed_chr${TASK_ID}.fam_ori
    sed &#39;s/_/\t/&#39; ${dir}/Imputed_Chromosomes/${data}_${imputetool}_imputed_chr${TASK_ID}.fam_ori | awk &#39;{print $2, $3, $4, $5, $6, $7}&#39;  &gt; ${dir}/Imputed_Chromosomes/${data}_${imputetool}_imputed_chr${TASK_ID}.fam
</code></pre>
<p>We then merge all the chromosomes into one file.</p>
<pre class="bash"><code>mkdir  -p  ${dir}/Imputed_plink_format
rm -f  $dir/Imputed_plink_format/${data}_all_imputed_plink_files.txt

for chr in $(seq 2 22)
do
echo  &quot;${dir}/Imputed_Chromosomes/${data}_${imputetool}_imputed_chr${chr}.bed \
${dir}/Imputed_Chromosomes/${data}_${imputetool}_imputed_chr${chr}.bim \
${dir}/Imputed_Chromosomes/${data}_${imputetool}_imputed_chr${chr}.fam&quot;  \
&gt;&gt; $dir/Imputed_plink_format/${data}_all_imputed_plink_files.t
xt
done

# merge the plink files of each chromosome
required=&quot;$required:$mergechunk_sub&quot;
merge_plink=&quot;plink --bfile ${dir}/Imputed_Chromosomes/${data}_${imputetool}_imputed_chr1  \
--merge-list $dir/Imputed_plink_format/${data}_all_imputed_plink_files.txt \
--allow-no-sex  --make-bed  \
--out  $dir/Imputed_plink_format/${data}_${imputetool}_imputed_autosomes &quot;

mergeplink_sub=`qsubshcom &quot;$merge_plink&quot; 1 100G merge_plink  1:00:00  &quot;$clusterconfig -wait=$required&quot;  `
</code></pre>
<p>Here we keep all the SNPs no matter of the imputation quality, so
that we won’t have missing SNPs which are in the predictor.</p>
</div>
</div>
<div id="pgs-profiling" class="section level1" number="3">
<h1><span class="header-section-number">3</span> PGS profiling</h1>
<p>PGS are profiled using PLINK with all the SBayesRC predictors in our
collection.</p>
<pre class="bash"><code>i=$SLURM_ARRAY_TASK_ID
traitfile=&quot;/QRISdata/Q6913/GCTB_predictor_list_for_batch_profiling.txt&quot;
trait=$(sed &quot;${i}q;d&quot; $traitfile | awk &#39;{print $1}&#39; )
predictor=$(sed  &quot;${i}q;d&quot;  $traitfile  | awk &#39;{print $3}&#39; )
outdir=PRS_all_GCTB

plink  \
--bfile  $bfile \
--score  ${predictor}  2 5 8  header sum    \
--out ${outdir}/${cohort}_${trait}_SBayesRC</code></pre>
<p>The parameters after your predictor file means</p>
<ul>
<li>2 5 8: the three useful columns in the predictor file.<br />
</li>
<li>header: The predictor file has a header row.<br />
</li>
<li>sum: Plink prefers to divide the score by the number of SNPs in
predictor. Using “sum” will prevent the division step.</li>
</ul>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
