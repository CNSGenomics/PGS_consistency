<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Low Coverage Whole Genome Sequencing data</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/lumen.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">PGS|Consistency</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="index.html">Introduction</a>
</li>
<li>
  <a href="0_PredictorPrep.html">Predictors</a>
</li>
<li>
  <a href="1_GRP_ChipData.html">HSU Data</a>
</li>
<li>
  <a href="2_QIMR_ChipData.html">QIMR Data</a>
</li>
<li>
  <a href="3_WGS.html">WGS data</a>
</li>
<li>
  <a href="4_LowPassSeq.html">lcWGS data</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Low Coverage Whole Genome Sequencing
data</h1>

</div>


<div id="introduction" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>As a trial for the validity of lcWGS, 48 samples previously genotyped
with Illumina GSAv2+MD were submitted for lcWGS including NA06997.
Library preparation was conducted in house at the UQ Human Studies Unit
and submitted for sequencing in UQ sequencing facility. The 48 samples
were pooled with multiplexing, and sequenced in one lane, setting paired
end 150bp reads on a SP flowcell using NovaSeq Illumina. Raw data were
transferred to us in FastQ format. All samples passed FastQC quality
threshold, and the reads were mapped to human genome assembly build 37
using the bwa in GATK. The GATK best practice pipeline was applied,
(sort using sambamba, mark-dup using GATK, Base Quality Score
Recalibration using GATK). Missing SNPs in data were imputed using
GLIMPSE25 against the downloaded HRCr1.1 imputation panel. GLIPMSE2 uses
the reference data to decide the chunks required to speed up imputation
in parallel jobs. It connects the imputed chunks into one data per
sample in VCF format. The SNP list in imputed data is the same as in the
HRC imputation panel.</p>
<p>Related reading:</p>
<p><a
href="https://www.genewiz.com/Public/Services/Next-Generation-Sequencing/Low-Pass-WholeGenomeSequencing/"
class="uri">https://www.genewiz.com/Public/Services/Next-Generation-Sequencing/Low-Pass-WholeGenomeSequencing/</a></p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/33770507/"
class="uri">https://pubmed.ncbi.nlm.nih.gov/33770507/</a></p>
</div>
<div id="alignment" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Alignment</h1>
<p>The first step to process low pass sequencing data is the same as
whole genome sequencing data. We used FastQC to check the quality and
they all passed. Then we aligned them to the human genome build 19 using
the best practice in GATK pipeline.</p>
<div id="tools-and-references" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> tools and
references</h2>
<pre class="sh"><code>## BWA
## http://bio-bwa.sourceforge.net
## Li H. and Durbin R. (2010) Fast and accurate long-read alignment with Burrows-Wheeler Transform. Bioinformatics, Epub. [PMID: 20080505]

# bwa-0.7.17.tar.bz2 is downloaded from 
#https://sourceforge.net/projects/bio-bwa/
tar -xf   bwa-0.7.17.tar.bz2 
cd bwa-0.7.17
make
cp bwa ~/bin/
##Version: 0.7.17-r1188

## sambamba

https://github.com/biod/sambamba/releases
wget https://github.com/biod/sambamba/releases/download/v0.8.2/sambamba-0.8.2-linux-amd64-static.gz
gunzip sambamba-0.8.2-linux-amd64-static.gz 
chmod u+x sambamba-0.8.2-linux-amd64-static 

## Picard
https://github.com/broadinstitute/picard/releases/tag/2.27.4
# click on picard.jar

##GATK
wget https://github.com/broadinstitute/gatk/releases/download/4.2.6.1/gatk-4.2.6.1.zip
unzip gatk-4.2.6.1.zip 

## bundle_source
## use Finder --&gt; go to server
ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/
## hg19
</code></pre>
</div>
<div id="align-the-reads" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> align the reads</h2>
<pre class="sh"><code>
i=$TASK_ID
WD=/scratch/60days/uqtlin5/X1WGS
ref=${WD}/Pipeline/ucsc.hg19.fasta
samplesheet=${WD}/samplesheet.txt
ncpus=10
cd $WD
sID=$( awk &#39;{print $1}&#39;   $samplesheet | head -n  $i   | tail -n 1 ) 
filename1=$( awk &#39;{print $2}&#39;   $samplesheet | head -n  $i   | tail -n 1 ) 
filename2=$( awk &#39;{print $3}&#39;   $samplesheet | head -n  $i   | tail -n 1 ) 

module load samtools
## index the reference 
## bwa index   Pipeline/ucsc.hg19.fasta

## run alignment
bwa mem -M -t $ncpus $ref  Raw_Data/$filename1  Raw_Data/$filename2 -R &quot;@RG\tID:${sID}\tPL:ILLUMINA\tSM:${sID}&quot; | samtools view -bS  &gt;  TMPDIR/${bamPrefix}.tmp.bam 
## run sort bam
sambamba sort -t $ncpus  -m 200G  -o  TMPDIR/${sID}.sort.bam   TMPDIR/${sID}.tmp.bam  
rm TMPDIR/${sID}.tmp.bam
## mark duplicates
java -jar picard.jar  MarkDuplicates   I=TMPDIR/${sID}.sort.bam    O=TMPDIR/${sID}.markdup.bam   M=TMPDIR/${sID}.dupStat  </code></pre>
</div>
<div id="recalibration" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> recalibration</h2>
<pre class="sh"><code>
i=$TASK_ID
WD=/scratch/60days/uqtlin5/X1WGS
cd $WD
samplesheet=${WD}/samplesheet.txt
sID=$( awk &#39;{print $1}&#39;   $samplesheet | head -n  $i   | tail -n 1 ) 
sortedNoDup=${WD}/TMPDIR/${sID}.markdup.bam
outDir=${WD}/TMPDIR/
ref=${WD}/Pipeline/hg19/ucsc.hg19.fasta

knownsite1=dbsnp_138.hg19
knownsite2=1000G_omni2.5.hg19.sites
knownsite3=1000G_phase1.indels.hg19.sites
knownsite4=1000G_phase1.snps.high_confidence.hg19.sites
knownsite5=CEUTrio.HiSeq.WGS.b37.bestPractices.hg19
knownsite6=dbsnp_138.hg19.excluding_sites_after_129
knownsite7=hapmap_3.3_hg19_pop_stratified_af
knownsite8=hapmap_3.3.hg19.sites
knownsite9=Mills_and_1000G_gold_standard.indels.hg19.sites
knownsite10=NA12878.HiSeq.WGS.bwa.cleaned.raw.subset.hg19.sites
knownsite11=NA12878.HiSeq.WGS.bwa.cleaned.raw.subset.hg19
knownsite12=NA12878.knowledgebase.snapshot.20131119.hg19

## get the recal table

${WD}/Pipeline/gatk-4.1.9.0/gatk BaseRecalibrator \
   -I  $sortedNoDup  \
   -R $ref \
   --known-sites hg19/${knownsite1}.vcf.gz \
   --known-sites hg19/${knownsite2}.vcf.gz \
   --known-sites hg19/${knownsite3}.vcf.gz \
   --known-sites hg19/${knownsite4}.vcf.gz \
   --known-sites hg19/${knownsite5}.vcf.gz \
   --known-sites hg19/${knownsite6}.vcf.gz \
   --known-sites hg19/${knownsite7}.vcf.gz \
   --known-sites hg19/${knownsite8}.vcf.gz \
   --known-sites hg19/${knownsite9}.vcf.gz \
   --known-sites hg19/${knownsite1}.vcf.gz \
   --known-sites hg19/${knownsite11}.vcf.gz \
   --known-sites hg19/${knownsite12}.vcf.gz \
   --showHidden   \
   -O  ${outDir}/${sID}_recal_data.table_1_12
 
## run recal 
gatk-4.1.9.0/gatk  ApplyBQSR \
   -R $ref  \
   -I $sortedNoDup \
   --bqsr-recal-file  ${outDir}/${sID}_recal_data.table_1_12   \
   -O  ${outDir}/${sID}_recal_1_12.bam
 
## plot recal
gatk-4.1.9.0/gatk   AnalyzeCovariates \
     -bqsr    ${outDir}/${sID}_recal_data.table_1_12    \
     -plots   ${outDir}/${sID}_recal_AnalyzeCovariates_1_12.pdf</code></pre>
</div>
</div>
<div id="use-glympse2-to-impute-data" class="section level1" number="3">
<h1><span class="header-section-number">3</span> use GLYMPSE2 to impute
data</h1>
<p>GLYMPSE2 is a new tool that takes the alignment files as input and
impute against a reference genome. GLYMPSE2 could take in haplotype
information. It’s much better than loimpute, which impute using the
called variants from alignment.</p>
<div id="use-reference-data-to-make-chunk-files" class="section level2"
number="3.1">
<h2><span class="header-section-number">3.1</span> use reference data to
make chunk files</h2>
<pre class="bash"><code>
chr=$SLURM_ARRAY_TASK_ID
cd /scratch/project/genetic_data_analysis/uqtlin5/Low_pass_sequencing
module load bcftools
mapfile=1000GP_Phase3/genetic_map_chr${chr}_combined_b37.txt
## HRC version
reffile=HRC.r1-1.EGA.GRCh37.chr${chr}.haplotypes.vcf.gz 

bcftools annotate --rename-chrs chr_name_conv.txt  /QRISdata/Q3046/Reference/HRC//$reffile     | bgzip &gt; chr_renamed_HRC_haplotype_vcf/${reffile}
tabix -p vcf chr_renamed_HRC_haplotype_vcf/${reffile}

./GLIMPSE2/GLIMPSE2_chunk_static  --input  chr_renamed_HRC_haplotype_vcf/$reffile \
--sequential  \
--region chr${chr}  \
--output chunks_HRC.chr${chr}.txt \
--map $mapfile
</code></pre>
</div>
<div id="chunk-the-reference-data" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> chunk the reference
data</h2>
<p>First we generate a chunk file merging from 22 chromosomes.</p>
<pre class="bash"><code>for ((i = 1; i &lt;= 22; i++)); do
  cat chunks_HRC.chr${i}.txt &gt;&gt; chunks_HRC.txt
done</code></pre>
<p>Then we will generate a chunked reference data based on each row of
this chunk file.</p>
<pre class="bash"><code>## for each chromosome we will run 

LINE=$SLURM_ARRAY_TASK_ID

cd /scratch/project/genetic_data_analysis/uqtlin5/Low_pass_sequencing
sample=NA06997_COR_S29
refdata=HRC
BAM=${sample}_recal_1_12.bam
chunkfile=chunks_${refdata}_chr1.txt
OUTDIR=GLIMPSE2_imputed_with_${refdata}
mkdir -p $OUTDIR
OUT=${OUTDIR}/${sample}_imputed
CHR=$(sed &quot;${LINE}q;d&quot; $chunkfile | awk &#39;{print $2}&#39; )
IRG=$(sed &quot;${LINE}q;d&quot; $chunkfile | awk &#39;{print $3}&#39; )
ORG=$(sed &quot;${LINE}q;d&quot; $chunkfile | awk &#39;{print $4}&#39; )
REGS=$(echo ${IRG} | cut -d&quot;:&quot; -f 2 | cut -d&quot;-&quot; -f1)
REGE=$(echo ${IRG} | cut -d&quot;:&quot; -f 2 | cut -d&quot;-&quot; -f2)

mapfile=1000GP_Phase3/genetic_map_${CHR}_combined_b37.txt

./GLIMPSE2/GLIMPSE2_split_reference_static \
  --reference  chr_renamed_${refdata}_haplotype_vcf/HRC.r1-1.EGA.GRCh37.${CHR}.haplotypes.vcf.gz \
  --map ${mapfile} \
  --input-region ${IRG} \
  --output-region ${ORG}  \
  --output  Splitted_${refdata}_panel/${refdata}
</code></pre>
</div>
<div id="pipeline-the-imputation-for-all-samples" class="section level2"
number="3.3">
<h2><span class="header-section-number">3.3</span> pipeline the
imputation for all samples</h2>
<p>The data will be imputed into chunks using each chunked reference
data.</p>
<pre class="bash"><code>## the whole genome has 771 chunks. 

LINE=$SLURM_ARRAY_TASK_ID

cd /scratch/project/genetic_data_analysis/uqtlin5/Low_pass_sequencing

refdata=HRC
OUTDIR=GLIMPSE2_imputed_with_${refdata}
chunkfile=chunks_${refdata}.txt
  
CHR=$(sed &quot;${LINE}q;d&quot; $chunkfile | awk &#39;{print $2}&#39; )
IRG=$(sed &quot;${LINE}q;d&quot; $chunkfile | awk &#39;{print $3}&#39; )
ORG=$(sed &quot;${LINE}q;d&quot; $chunkfile | awk &#39;{print $4}&#39; )
REGS=$(echo ${IRG} | cut -d&quot;:&quot; -f 2 | cut -d&quot;-&quot; -f1)
REGE=$(echo ${IRG} | cut -d&quot;:&quot; -f 2 | cut -d&quot;-&quot; -f2)

while IFS= read -r BAM; do

  ./GLIMPSE2/GLIMPSE2_phase_static \
  --bam-file  BQRS/${BAM}_recal_1_12.bam \
  --reference Splitted_${refdata}_panel/${refdata}_${CHR}_${REGS}_${REGE}.bin \
  --output ${OUTDIR}/${BAM}_imputed_${CHR}_${REGS}_${REGE}.bcf

done &lt; bam_file_list.txt
</code></pre>
</div>
<div id="ligate-the-imputed-chunks" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> ligate the imputed
chunks</h2>
<p>The imputed chunks are then concatenated together into a bcf file for
each sample.</p>
<pre class="bash"><code>
# ligate

while IFS= read -r BAM; do

LST=GLIMPSE2_HRC_ligate/${BAM}_list.txt
ls -1v GLIMPSE2_imputed_with_HRC/${BAM}_imputed_*.bcf &gt; ${LST}
OUT=GLIMPSE2_HRC_ligate/${BAM}_ligated.bcf

job_name=&quot;ligate_&quot;${BAM}  
ligatesub=`qsubshcom &quot;  ./GLIMPSE2/GLIMPSE2_ligate_static --input ${LST} --output $OUT &quot; 1 150G $job_name 24:00:00 &quot;  &quot;   `

done &lt; bam_file_list.txt
</code></pre>
</div>
<div id="reformat-the-data" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> reformat the
data</h2>
<p>For the next step, files are converted from bcf format to vcf
format</p>
<pre class="bash"><code>## convert bcf to vcf
while IFS= read -r BAM; do
 bcftools convert -O v -o GLIMPSE2_HRC_ligate/${BAM}_ligated.vcf   GLIMPSE2_HRC_ligate/${BAM}_ligated.bcf
done &lt; bam_file_list.txt</code></pre>
</div>
<div id="extract-snps" class="section level2" number="3.6">
<h2><span class="header-section-number">3.6</span> extract SNPs</h2>
<p>To reduce the computation burdon, I extracted the 7.3M SNPs from the
data.</p>
<pre class="bash"><code>
## convert bcf to vcf
while IFS= read -r BAM; do

grep &quot;^#&quot; GLIMPSE2_HRC_ligate/${BAM}_ligated.vcf &gt; ${BAM}_ligated_dbSNP.vcf 
grep -v &quot;^#&quot;  GLIMPSE2_HRC_ligate/${BAM}_ligated.vcf | grep -w -f SNPs_in_7.4M.txt &gt;&gt; ${BAM}_ligated_dbSNP.vcf 

done &lt; bam_file_list.txt</code></pre>
<p>Data of all the samples are merged into one file.</p>
<pre class="bash"><code>## merge all samples
## did in both folder GLIMPSE2_HRC_ligate_vcf and dbSNP_of_GLIMPSE2_imputed_with_HRC

for file in *.vcf; do
    bgzip -c &quot;$file&quot; &gt; &quot;${file}.gz&quot;
    bcftools index &quot;${file}.gz&quot;

done

qsubshcom &quot; bcftools merge -o LPS_all48samples.vcf.gz -O v -@ 4  *.vcf.gz &quot;  4 150G &quot;merge&quot; 56:00:00 &quot; &quot;   
bcftools merge -o LPS_all48samples.vcf.gz -O v   *.vcf.gz
</code></pre>
</div>
</div>
<div id="profile-prs" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Profile PRS</h1>
<p>PRS are profiled from the merged vcf file directly.</p>
<pre class="bash"><code>i=$SLURM_ARRAY_TASK_ID
cd /scratch/project/genetic_data_analysis/uqtlin5/Low_pass_sequencing

traitfile=&quot;GCTB_SBayesRC_predictors.txt&quot;
trait=$(sed &quot;${i}q;d&quot; $traitfile | awk &#39;{print $1}&#39; )
predictor=$(sed &quot;${i}q;d&quot; $traitfile | awk &#39;{print $2}&#39; )
outdir=PRS_all_GCTB
input=dbSNP_of_GLIMPSE2_imputed_with_HRC/LPS_dbSNP_set.vcf.gz
cohort=&quot;LPS&quot;

mkdir -p $outdir

plink \
   --vcf  $input \
   --const-fid  \
   --score  $predictor    2 5 8 header sum   \
   --out ${outdir}/${cohort}_${trait}_SBayesRC
</code></pre>
</div>
<div id="get-corresponding-samples-from-chip-data"
class="section level1" number="5">
<h1><span class="header-section-number">5</span> get corresponding
samples from chip data</h1>
<p>46 out of the 47 samples in this pilot study were genotyped using GSA
chip in HSU lab. Here we profiled PGS from the imputed chip data.</p>
<p>The data were processed in the same way as other HSU data.</p>
<pre class="bash"><code>traitfile=&quot;../GCTB_SBayesRC_predictors.txt&quot;
trait=$(sed &quot;${i}q;d&quot; $traitfile | awk &#39;{print $1}&#39; )
predictor=$(sed  &quot;${i}q;d&quot;  $traitfile  | awk &#39;{print $2}&#39; )
outdir=PRS_all_GCTB
mkdir -p $outdir
cohort=MND_B3
input=MND_B3_GSA_imputed_fixed

plink \
   --bfile  $input \
   --score  $predictor  2 5 8  header sum    \
   --out ${outdir}/${cohort}_${trait}_SBayesRC
</code></pre>
</div>
<div id="compare-pgs-between-lcwgs-vs.-gsa-chip" class="section level1"
number="6">
<h1><span class="header-section-number">6</span> Compare PGS between
lcWGS vs. GSA chip</h1>
<p>There are 48 samples in the LPS pilot set.</p>
<p>1 of them is a ceph control</p>
<p>46 of them are also available in the MND B3 GSA data set</p>
<p>The other 1 is available in ALS_AUS old data. (3728601, or
MND_CON_252)</p>
<div id="ancestry-of-als-samples" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> ancestry of ALS
samples</h2>
<p>Here is the 46 overlap samples with PC projected to 1000g. They are
all from Europeans.</p>
<p><img src="Figures/Ancestry_of_samples_in_LPS&amp;GSAv2.png" /></p>
</div>
<div id="correlation" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> correlation</h2>
<div id="standardize-the-two-data" class="section level3"
number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> standardize the two
data</h3>
<pre class="r"><code>library(reshape2)

standardization.data = read.csv(&quot;Data/LifeLines_MEAN_and_SD_of_traits_for_standardization.csv&quot;)

## input PRS from low pass
lps.prs = read.csv(&quot;Data/LowPass/LPS_all_141_traits_GCTB_PRS.csv&quot;)
colnames(lps.prs)[1] = &quot;FID&quot;
lps.prs$IID &lt;- sub(&quot;_.*&quot;, &quot;&quot;, lps.prs$FID)
row.names(lps.prs) = lps.prs$IID
lps.prs = lps.prs[,-c(1:2)]

lps.prs = lps.prs[,colnames(lps.prs) %in%standardization.data$trait ]
standardization.data= standardization.data[  match( colnames(lps.prs) , standardization.data$trait),]

lps.prs.norm = sweep(
  sweep (  lps.prs,  
          2, standardization.data$mean),  
  2, standardization.data$sd, FUN = &#39;/&#39;)

lps.prs.norm$IID &lt;- row.names(lps.prs.norm)
melted.lps.prs.norm = reshape2::melt(lps.prs.norm, id.vars = &quot;IID&quot; ) 
melted.lps.prs.norm$value = as.numeric(melted.lps.prs.norm$value)</code></pre>
<pre class="r"><code>## input inhouse imputed GSA data
mnd.b3.bcc = read.csv(&quot;Data/LowPass/MND_B3_BCC_GSA_all_141_traits_GCTB_PRS.csv&quot;, row.names = 1)

mnd.b3.bcc &lt;- mnd.b3.bcc %&gt;%
  separate(IID, into = c(&quot;part1&quot;, &quot;part2&quot;, &quot;part3&quot;, &quot;part4&quot;), sep = &quot;_&quot;, fill = &quot;right&quot;) %&gt;%
  mutate(
    V1 = part2,                 # Combine part1 and part2 for V1
    IID = if_else(is.na(part4), part3, paste(part3, part4, sep = &quot;_&quot;)) # Combine remaining parts for Study_ID
  ) %&gt;%
  select(V1,IID, everything(),-part1, -part2, -part3, -part4, -V3, -V4, -V5, -V6)

row.names(mnd.b3.bcc) = mnd.b3.bcc$IID
mnd.b3.bcc = mnd.b3.bcc[,-c(1:2)]
mnd.b3.bcc = mnd.b3.bcc[,colnames(mnd.b3.bcc) %in%standardization.data$trait ]
standardization.data= standardization.data[  match( colnames(mnd.b3.bcc) , standardization.data$trait),]

mnd.b3.bcc.norm = sweep(
  sweep (  mnd.b3.bcc,  
          2, standardization.data$mean),  
  2, standardization.data$sd, FUN = &#39;/&#39;)

mnd.b3.bcc.norm$IID &lt;- row.names(mnd.b3.bcc.norm)
melted.mnd.b3.bcc.norm = reshape2::melt(mnd.b3.bcc.norm, id.vars = &quot;IID&quot; )
melted.mnd.b3.bcc.norm$value = as.numeric(melted.mnd.b3.bcc.norm$value)</code></pre>
</div>
<div id="select-traits" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> select traits</h3>
<pre class="r"><code>predictor.list = read.csv(&quot;Tables/SupTable2_Predictors.csv&quot;)
included_traits = predictor.list$Predictor
## grouping traits
traits_binary = predictor.list[which(predictor.list$QorB == &quot;Binary&quot; ),&quot;Predictor&quot;]
traits_quanti = predictor.list[which(predictor.list$Location == &quot;Uno_Traits/Quantitative_Traits/&quot;),&quot;Predictor&quot;]
traits_35bm   = predictor.list[which(predictor.list$Location == &quot;Lot_Traits/UKB_35BM_2021/&quot;),&quot;Predictor&quot;]
traits_ppp   = predictor.list[which(predictor.list$Location == &quot;Lot_Traits/UKB_PPP_2022/&quot;),&quot;Predictor&quot;]
traits_fa   = predictor.list[which(predictor.list$Location == &quot;Lot_Traits/UKB_Fatty_Acids/&quot;),&quot;Predictor&quot;]

## select data
melted.mnd.b3.bcc.norm = melted.mnd.b3.bcc.norm[melted.mnd.b3.bcc.norm$variable %in% included_traits,]
melted.lps.prs.norm = melted.lps.prs.norm[melted.lps.prs.norm$variable %in% included_traits,]</code></pre>
</div>
<div id="merge-the-two-data" class="section level3" number="6.2.3">
<h3><span class="header-section-number">6.2.3</span> merge the two
data</h3>
<pre class="r"><code>colnames(melted.mnd.b3.bcc.norm)[3] = &quot;GSAv2&quot;
colnames(melted.lps.prs.norm)[3] = &quot;LPS&quot;

melted.both =  merge(melted.lps.prs.norm, 
                     melted.mnd.b3.bcc.norm[, c(&quot;IID&quot;, &quot;variable&quot;, &quot;GSAv2&quot;)], 
                by = c(&quot;IID&quot;, &quot;variable&quot;), 
                all.x = TRUE)

melted.both$LPS = as.numeric(melted.both$LPS)
melted.both$GSAv2 = as.numeric(melted.both$GSAv2)
melted.both$Trait = predictor.list[match(melted.both$variable, predictor.list$Predictor),&quot;Label&quot;]
melted.SALSA = na.omit(melted.both)</code></pre>
</div>
<div id="compare-across-traits" class="section level3" number="6.2.4">
<h3><span class="header-section-number">6.2.4</span> compare across
traits</h3>
<pre class="r"><code>result &lt;- melted.SALSA %&gt;%
  group_by(variable) %&gt;%
  summarise(correlation = cor(LPS, GSAv2, use = &quot;complete.obs&quot;), .groups = &quot;drop&quot;)
result = data.frame(result)
result$Trait = predictor.list[match(result$variable, predictor.list$Predictor),&quot;Label&quot;]
result$cor = paste0(&quot;cor=&quot;, round(result$correlation, 2) )
result %&gt;% filter(correlation &lt; 0.95) %&gt;% arrange((correlation))</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["variable"],"name":[1],"type":["fct"],"align":["left"]},{"label":["correlation"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Trait"],"name":[3],"type":["chr"],"align":["left"]},{"label":["cor"],"name":[4],"type":["chr"],"align":["left"]}],"data":[{"1":"C4_01","2":"0.3673743","3":"Complement Component 4","4":"cor=0.37"},{"1":"CeliacDisease_01","2":"0.7931693","3":"Celiac disease","4":"cor=0.79"},{"1":"PBC_01","2":"0.8986654","3":"Primary biliary cirrhosis","4":"cor=0.9"},{"1":"C3_01","2":"0.9082594","3":"Complement Component 3","4":"cor=0.91"},{"1":"UKB_PPP_2022_TNF","2":"0.9117453","3":"TNF-alpha","4":"cor=0.91"},{"1":"UKB_PPP_2022_IL10","2":"0.9239051","3":"IL-10","4":"cor=0.92"},{"1":"SLE_01","2":"0.9314831","3":"Systemic lupus erythematosus","4":"cor=0.93"},{"1":"UKB_PPP_2022_IL15","2":"0.9343848","3":"IL-15","4":"cor=0.93"},{"1":"UKB_35BM_2021_Non_albumin_protein","2":"0.9456492","3":"Non-albumin protein","4":"cor=0.95"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>hist(result$correlation)</code></pre>
<p><img src="4_LowPassSeq_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>mean is 0.9709689</p>
<p>SD is 0.062162</p>
</div>
<div id="across-samples" class="section level3" number="6.2.5">
<h3><span class="header-section-number">6.2.5</span> across samples</h3>
<pre class="r"><code>result.c.samples &lt;- melted.SALSA %&gt;%
  group_by(IID) %&gt;%
  summarise(correlation = cor(LPS, GSAv2))
summary(result.c.samples$correlation)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.9350  0.9648  0.9733  0.9697  0.9782  0.9879</code></pre>
<pre class="r"><code>hist(result.c.samples$correlation)</code></pre>
<p><img src="4_LowPassSeq_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
</div>
</div>
<div id="plot" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> plot</h2>
<div id="binary" class="section level3" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> binary</h3>
<pre class="r"><code>nbm.plot = ggplot(data = melted.both[ melted.both$variable %in% traits_binary,], aes(x = GSAv2, y = LPS)) +
  facet_wrap(~Trait,  ncol= 6, labeller = labeller(Trait = function(x) str_wrap(x, width = 20))) + 
  geom_abline(intercept = 0, slope = 1, color = &quot;lightblue&quot;) +
  geom_point(size = 0.8) + 
  xlim(-3,3) + ylim(-3,3) + 
    theme_classic(base_size = 12) +
theme(
   panel.grid.major = element_blank(), # Remove major grid lines
    panel.grid.minor = element_blank(), # Remove minor grid lines
    plot.title = element_text(hjust = 0.5),
    axis.title = element_text(),
    axis.text = element_text(size = 12),
    strip.background = element_blank()
  ) +
  geom_text(data = result[result$variable %in% traits_binary,],aes(x = -1.5, y = 2, label = cor) )
nbm.plot</code></pre>
<pre><code>## Warning: Removed 81 rows containing missing values or values outside the scale range
## (`geom_point()`).</code></pre>
<p><img src="4_LowPassSeq_files/figure-html/unnamed-chunk-20-1.png" width="1152" /></p>
<pre class="r"><code>#ggsave(plot = nbm.plot,filename =  &quot;Figures/SupFig2_lcWGS_vs_GSAvs_binary_traits.jpeg&quot; , width = 12, height = 13)</code></pre>
</div>
<div id="quantitative" class="section level3" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> quantitative</h3>
<pre class="r"><code>nbm.plot = ggplot(data = melted.both[ melted.both$variable %in% traits_quanti,], aes(x = GSAv2, y = LPS)) +
  facet_wrap(~Trait,  ncol= 6, labeller = labeller(Trait = function(x) str_wrap(x, width = 20))) + 
  geom_abline(intercept = 0, slope = 1, color = &quot;lightblue&quot;) +
  geom_point(size = 0.8) + 
  xlim(-3,3) + ylim(-3,3) + 
    theme_classic(base_size = 12) +
theme(
   panel.grid.major = element_blank(), # Remove major grid lines
    panel.grid.minor = element_blank(), # Remove minor grid lines
    plot.title = element_text(hjust = 0.5),
    axis.title = element_text(),
    axis.text = element_text(size = 12),
    strip.background = element_blank()
  ) +
  geom_text(data = result[result$variable %in% traits_quanti,],aes(x = -1.5, y = 2, label = cor) )
nbm.plot</code></pre>
<pre><code>## Warning: Removed 52 rows containing missing values or values outside the scale range
## (`geom_point()`).</code></pre>
<p><img src="4_LowPassSeq_files/figure-html/unnamed-chunk-21-1.png" width="1152" /></p>
<pre class="r"><code>#ggsave(plot = nbm.plot,filename =  &quot;Figures/SupFig2_lcWGS_vs_GSAvs_quantitative_traits.jpeg&quot; , width = 12, height = 9)</code></pre>
</div>
<div id="biomarker" class="section level3" number="6.3.3">
<h3><span class="header-section-number">6.3.3</span> Biomarker</h3>
<pre class="r"><code>nbm.plot = ggplot(data = melted.both[ melted.both$variable %in% traits_35bm,], aes(x = GSAv2, y = LPS)) +
  facet_wrap(~Trait,  ncol= 6, labeller = labeller(Trait = function(x) str_wrap(x, width = 20))) + 
  geom_abline(intercept = 0, slope = 1, color = &quot;lightblue&quot;) +
  geom_point(size = 0.8) + 
  xlim(-3,3) + ylim(-3,3) + 
    theme_classic(base_size = 12) +
theme(
   panel.grid.major = element_blank(), # Remove major grid lines
    panel.grid.minor = element_blank(), # Remove minor grid lines
    plot.title = element_text(hjust = 0.5),
    axis.title = element_text(),
    axis.text = element_text(size = 12),
    strip.background = element_blank()
  ) +
  geom_text(data = result[result$variable %in% traits_35bm,],aes(x = -1.5, y = 2, label = cor) )
nbm.plot</code></pre>
<pre><code>## Warning: Removed 72 rows containing missing values or values outside the scale range
## (`geom_point()`).</code></pre>
<p><img src="4_LowPassSeq_files/figure-html/unnamed-chunk-22-1.png" width="1152" /></p>
<pre class="r"><code>#ggsave(plot = nbm.plot,filename =  &quot;Figures/SupFig2_lcWGS_vs_GSAvs_35BM.jpeg&quot; , width = 12, height = 13)</code></pre>
</div>
<div id="fatty-acid" class="section level3" number="6.3.4">
<h3><span class="header-section-number">6.3.4</span> fatty acid</h3>
<pre class="r"><code>nbm.plot = ggplot(data = melted.both[ melted.both$variable %in% traits_fa,], aes(x = GSAv2, y = LPS)) +
  facet_wrap(~Trait,  ncol= 6, labeller = labeller(Trait = function(x) str_wrap(x, width = 20))) + 
  geom_abline(intercept = 0, slope = 1, color = &quot;lightblue&quot;) +
  geom_point(size = 0.8) + 
  xlim(-3,3) + ylim(-3,3) + 
    theme_classic(base_size = 12) +
theme(
   panel.grid.major = element_blank(), # Remove major grid lines
    panel.grid.minor = element_blank(), # Remove minor grid lines
    plot.title = element_text(hjust = 0.5),
    axis.title = element_text(),
    axis.text = element_text(size = 12),
    strip.background = element_blank()
  ) +
  geom_text(data = result[result$variable %in% traits_fa,],aes(x = -1.5, y = 2, label = cor) )
nbm.plot</code></pre>
<pre><code>## Warning: Removed 37 rows containing missing values or values outside the scale range
## (`geom_point()`).</code></pre>
<p><img src="4_LowPassSeq_files/figure-html/unnamed-chunk-23-1.png" width="1152" /></p>
<pre class="r"><code>#ggsave(plot = nbm.plot,filename =  &quot;Figures/SupFig2_lcWGS_vs_GSAvs_FattyAcid_traits.jpeg&quot; , width = 12, height = 6.5)</code></pre>
</div>
<div id="ppp" class="section level3" number="6.3.5">
<h3><span class="header-section-number">6.3.5</span> PPP</h3>
<pre class="r"><code>nbm.plot = ggplot(data = melted.both[ melted.both$variable %in% traits_ppp,], aes(x = GSAv2, y = LPS)) +
  facet_wrap(~Trait,  ncol= 6, labeller = labeller(Trait = function(x) str_wrap(x, width = 20))) + 
  geom_abline(intercept = 0, slope = 1, color = &quot;lightblue&quot;) +
  geom_point(size = 0.8) + 
  xlim(-3,3) + ylim(-3,3) + 
    theme_classic(base_size = 12) +
theme(
   panel.grid.major = element_blank(), # Remove major grid lines
    panel.grid.minor = element_blank(), # Remove minor grid lines
    plot.title = element_text(hjust = 0.5),
    axis.title = element_text(),
    axis.text = element_text(size = 12),
    strip.background = element_blank()
  ) +
  geom_text(data = result[result$variable %in% traits_ppp,],aes(x = -1.5, y = 2, label = cor) )
nbm.plot</code></pre>
<pre><code>## Warning: Removed 21 rows containing missing values or values outside the scale range
## (`geom_point()`).</code></pre>
<p><img src="4_LowPassSeq_files/figure-html/unnamed-chunk-24-1.png" width="1152" /></p>
<pre class="r"><code>#ggsave(plot = nbm.plot,filename =  &quot;Figures/SupFig2_lcWGS_vs_GSAvs_PPP.jpeg&quot; , width = 12, height = 4.5)</code></pre>
</div>
<div id="per-person-plot" class="section level3" number="6.3.6">
<h3><span class="header-section-number">6.3.6</span> per person
plot</h3>
<pre class="r"><code>person.plot = ggplot(data = melted.both[!melted.both$IID %in% c(&quot;NA06997&quot;,&quot;3728601&quot; ) ,], aes(x = GSAv2, y = LPS)) +
  facet_wrap(~IID,  ncol= 6) + 
  geom_abline(intercept = 0, slope = 1, color = &quot;lightblue&quot;) +
  geom_point(size = 0.8) + 
  xlim(-3,3) + ylim(-3,3) + 
    theme_classic(base_size = 12) +
theme(
   panel.grid.major = element_blank(), # Remove major grid lines
    panel.grid.minor = element_blank(), # Remove minor grid lines
    plot.title = element_text(hjust = 0.5),
    axis.title = element_text(),
    axis.text = element_text(size = 12),
    strip.background = element_blank()
  ) 

person.plot</code></pre>
<pre><code>## Warning: Removed 33 rows containing missing values or values outside the scale range
## (`geom_point()`).</code></pre>
<p><img src="4_LowPassSeq_files/figure-html/unnamed-chunk-25-1.png" width="1152" /></p>
<pre class="r"><code>#ggsave(plot = person.plot,filename =  &quot;Figures/SupFig2_lcWGS_vs_GSAvs_per_person.jpeg&quot; , width = 12, height = 16)</code></pre>
</div>
</div>
</div>
<div id="find-correlation-outliers" class="section level1" number="7">
<h1><span class="header-section-number">7</span> Find correlation
outliers</h1>
<pre class="r"><code>result = data.frame(result)

ggplot(data = melted.SALSA[melted.SALSA$variable %in% result[which(result$correlation &lt; 0.95), &quot;variable&quot;],], aes(x = GSAv2, y = LPS)) + 
  geom_point(size = 0.1) + 
  facet_wrap(~variable, ncol = 4) + 
  xlim(-3,3) + ylim(-3,3)</code></pre>
<pre><code>## Warning: Removed 2 rows containing missing values or values outside the scale range
## (`geom_point()`).</code></pre>
<p><img src="4_LowPassSeq_files/figure-html/unnamed-chunk-26-1.png" width="1152" /></p>
</div>
<div id="pgs-correlation-without-mhc-region" class="section level1"
number="8">
<h1><span class="header-section-number">8</span> PGS correlation without
MHC region</h1>
<p>We excluded the MHC region when profile PGS of C4, Celiac Disease and
Primary biliary cirrhosis, respectively.</p>
<pre class="r"><code>library(data.table)
a = data.frame(fread(&quot;../CeliacDisease_01_SBayesRC.snpRes&quot;))
mhc.snp = (a[which(a$Chrom ==6  &amp; a$Position &gt;28477797   &amp; a$Position&lt;33448354),])
write.table(mhc.snp$Name, file=&quot;MHC.SNPs.txt&quot;, quote = F, sep =&quot;\t&quot;, row.names = F, col.names = F)</code></pre>
<pre class="bash"><code>
outdir=PRS_withoutMHC
 mkdir -p $outdir
exlist=PRS_withoutMHC/MHC.SNPs.txt

for trait in PBC_01 CeliacDisease_01 C4_01
do
  echo &quot;Processing trait: $sample&quot;
  predictor=${trait}_SBayesRC.snpRes
  
  ## chip data
  cohort=MND_B3
  input=MND_B3_BCC_GSA_imputed_autosomes_fixed
  plink \
     --bfile  $input \
     --score  $predictor  2 5 8  header sum    \
     --exclude $exlist  \
     --out ${outdir}/${cohort}_${trait}_SBayesRC_noMHC
  
  ## LPS data
  input=LPS_dbSNP_set.vcf.gz
  cohort=&quot;LPS&quot;
  plink \
     --vcf  $input \
     --const-fid  \
     --score  $predictor    2 5 8 header sum   \
     --exclude $exlist  \
     --out ${outdir}/${cohort}_${trait}_SBayesRC_noMHC
done
</code></pre>
<pre class="r"><code>library(tidyr)
library(stringr)
library(dplyr)

outputtable = data.frame(
traits=c(&quot;C4_01&quot;, &quot;CeliacDisease_01&quot;, &quot;PBC_01&quot; ),
cor = NA)

for(i in 1:3){ 
  trait=outputtable[i,1]
  cohort1=&quot;LPS&quot;
  cohort2=&quot;MND_B3&quot;
lps=read.table(paste0(&quot;PRS_withoutMHC/&quot;, cohort1,&quot;_&quot;, trait, &quot;_SBayesRC_noMHC.profile&quot;), header = T )
chip=read.table(paste0(&quot;PRS_withoutMHC/&quot;,cohort2,&quot;_&quot;, trait, &quot;_SBayesRC_noMHC.profile&quot;), header = T )
lps = lps %&gt;%
  separate(IID, into = c(&quot;part1&quot;, &quot;part2&quot;, &quot;part3&quot;, &quot;part4&quot;), sep = &quot;_&quot;, fill = &quot;right&quot;) %&gt;%
  mutate( ID = part1) 
chip = chip %&gt;%
  separate(IID, into = c(&quot;part1&quot;, &quot;part2&quot;, &quot;part3&quot;), sep = &quot;_&quot;, fill = &quot;right&quot;) %&gt;%
  mutate( ID = part3) 
lps$ChipPRS = chip[match(lps$ID, chip$ID),&quot;SCORESUM&quot;]
outputtable[i,2]  =cor(lps$SCORESUM, lps$ChipPRS, use = &quot;complete.obs&quot;)
}</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">–</th>
<th align="center">full PRS</th>
<th align="center">PRS without MHC SNPs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">C4</td>
<td align="center">0.367</td>
<td align="center">0.997</td>
</tr>
<tr class="even">
<td align="right">Celiac Disease</td>
<td align="center">0.793</td>
<td align="center">0.997</td>
</tr>
<tr class="odd">
<td align="right">Primary biliary cirrhosis</td>
<td align="center">0.898</td>
<td align="center">0.994</td>
</tr>
</tbody>
</table>
<p>This observation suggest that the main difference came from the low
quality imputation in MHC region.</p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
